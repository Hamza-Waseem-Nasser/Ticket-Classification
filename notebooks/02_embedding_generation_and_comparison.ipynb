{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "068e3e84",
   "metadata": {},
   "source": [
    "# ğŸš€ Phase 2: Multi-Model Embedding Generation & FAISS Search\n",
    "\n",
    "**Objective**: Generate embeddings using multiple models, create FAISS indices, and evaluate embedding similarity performance for our AI-enhanced Saber category descriptions.\n",
    "\n",
    "## ğŸ¯ **What We'll Do:**\n",
    "\n",
    "1. **Load AI-Enhanced Data** â†’ Saber categories with rich semantic descriptions\n",
    "2. **Multi-Model Embedding Generation** â†’ Test OpenAI, Sentence Transformers, Arabic models\n",
    "3. **FAISS Index Creation** â†’ Optimize for fast similarity search\n",
    "4. **Embedding Quality Evaluation** â†’ Compare models on real user queries\n",
    "5. **Performance Benchmarking** â†’ Speed vs accuracy trade-offs\n",
    "\n",
    "## ğŸ“Š **Expected Outcome:**\n",
    "Production-ready embedding pipeline with optimal model selection for Arabic-English incident classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f15e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Basic libraries imported successfully\n",
      "ğŸ“‚ Current working directory: c:\\Users\\ASUS\\Classification\\notebooks\n",
      "ğŸ”‘ OpenAI API Key: âœ… Found\n",
      "ğŸ”‘ Gemini API Key: âœ… Found\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Basic libraries imported successfully\")\n",
    "print(f\"ğŸ“‚ Current working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ”‘ OpenAI API Key: {'âœ… Found' if os.getenv('OPENAI_API_KEY') else 'âŒ Not Found'}\")\n",
    "print(f\"ğŸ”‘ Gemini API Key: {'âœ… Found' if os.getenv('GEMINI_API_KEY') else 'âŒ Not Found'}\")\n",
    "\n",
    "# We'll import custom modules later as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84e41f",
   "metadata": {},
   "source": [
    "## ğŸ“Š 1. Load AI-Enhanced Saber Categories Data\n",
    "\n",
    "Load the data with rich semantic descriptions generated in Phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e80ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading AI-enhanced Saber categories data...\n",
      "âœ… Data loaded successfully!\n",
      "ğŸ“‹ Dataset shape: (100, 12)\n",
      "ğŸ“ Columns: ['Service', 'Category', 'SubCategory', 'SubCategory_Prefix ', 'SubCategory_Keywords', 'SubCategory2', 'SubCategory2_Prefix ', 'SubCategory2_Keywords', 'raw_text', 'structured_text', 'user_query_format', 'user_style_description']\n",
      "\n",
      "ğŸ“„ Sample AI-Generated Descriptions:\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Category 1: Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø§Ù„Ù‡ÙŠØ¦Ø©\n",
      "   Service: SASO - Products Safety and Certification\n",
      "   Description Length: 2032 chars\n",
      "   Description: Here's a semantically rich description designed for high embedding similarity with user queries related to SASO Saber, specifically focusing on \"Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø§Ù„Ù‡ÙŠØ¦Ø©\" (Certificates Issued by the...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“‹ Category 2: Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©\n",
      "   Service: SASO - Products Safety and Certification\n",
      "   Description Length: 2207 chars\n",
      "   Description: Okay, here's a semantically rich description designed for high embedding similarity with user queries related to SASO, Saber, and Conformity Assessment Bodies (CABs), incorporating Arabic and English:...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“‹ Category 3: Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø§Ù„Ù‡ÙŠØ¦Ø©\n",
      "   Service: SASO - Products Safety and Certification\n",
      "   Description Length: 1558 chars\n",
      "   Description: Here's a semantically rich description for the \"Ø´Ù‡Ø§Ø¯Ø§Øª ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø§Ù„Ù‡ÙŠØ¦Ø©\" Saber category, designed for high embedding similarity with real user queries:\n",
      "\n",
      "**Description:**\n",
      "\n",
      "\"Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“Š Description Statistics:\n",
      "   Total categories: 100\n",
      "   Average description length: 1783 characters\n",
      "   Min length: 1349 characters\n",
      "   Max length: 2232 characters\n",
      "   Median length: 1792 characters\n",
      "\n",
      "ğŸ” Quality Check:\n",
      "   Successful descriptions: 100\n",
      "   Failed descriptions: 0\n",
      "\n",
      "âœ… Data ready for embedding generation!\n"
     ]
    }
   ],
   "source": [
    "# Load AI-enhanced data and experiment results from Phase 1\n",
    "\n",
    "def load_latest_experiment(experiment_type='user_optimized'):\n",
    "    \"\"\"Load the latest experiment results from Phase 1\"\"\"\n",
    "    experiment_dir = Path('../results/experiments/phase1_descriptions')\n",
    "    \n",
    "    if experiment_dir.exists():\n",
    "        # Find latest experiment file matching the type\n",
    "        pattern = f'{experiment_type}_*.csv'\n",
    "        experiment_files = list(experiment_dir.glob(pattern))\n",
    "        \n",
    "        if experiment_files:\n",
    "            # Get the most recent file\n",
    "            latest_file = max(experiment_files, key=lambda x: x.stat().st_mtime)\n",
    "            print(f\"ğŸ“Š Found experiment files: {len(experiment_files)}\")\n",
    "            print(f\"ğŸ“ Loading latest: {latest_file.name}\")\n",
    "            return pd.read_csv(latest_file, encoding='utf-8'), latest_file\n",
    "    \n",
    "    # Fallback to main results file\n",
    "    data_file = '../results/saber_categories_with_user_style_descriptions.csv'\n",
    "    print(f\"ğŸ“Š Loading main results file: {data_file}\")\n",
    "    return pd.read_csv(data_file, encoding='utf-8'), data_file\n",
    "\n",
    "# Load the data\n",
    "df, data_source = load_latest_experiment()\n",
    "\n",
    "print(f\"âœ… Data loaded successfully!\")\n",
    "print(f\"ğŸ“‹ Dataset shape: {df.shape}\")\n",
    "print(f\"ğŸ“ Source: {data_source}\")\n",
    "print(f\"ğŸ“ Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check which description column to use\n",
    "description_columns = [col for col in df.columns if 'description' in col.lower()]\n",
    "print(f\"ğŸ“„ Available description columns: {description_columns}\")\n",
    "\n",
    "# Use the generated description column\n",
    "if 'generated_description' in df.columns:\n",
    "    description_col = 'generated_description'\n",
    "elif 'user_style_description' in df.columns:\n",
    "    description_col = 'user_style_description'\n",
    "else:\n",
    "    description_col = description_columns[0] if description_columns else 'raw_text'\n",
    "\n",
    "print(f\"ğŸ¯ Using description column: {description_col}\")\n",
    "\n",
    "# Display sample descriptions\n",
    "print(f\"\\nğŸ“„ Sample AI-Generated Descriptions:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(min(3, len(df))):\n",
    "    row = df.iloc[i]\n",
    "    description = str(row[description_col])\n",
    "    print(f\"\\nğŸ“‹ Category {i+1}: {row['SubCategory']}\")\n",
    "    print(f\"   Service: {row['Service']}\")\n",
    "    print(f\"   Description Length: {len(description)} chars\")\n",
    "    print(f\"   Description: {description[:200]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nğŸ“Š Description Statistics:\")\n",
    "descriptions = df[description_col].astype(str)\n",
    "desc_lengths = [len(desc) for desc in descriptions]\n",
    "print(f\"   Total categories: {len(df)}\")\n",
    "print(f\"   Average description length: {np.mean(desc_lengths):.0f} characters\")\n",
    "print(f\"   Min length: {min(desc_lengths)} characters\")\n",
    "print(f\"   Max length: {max(desc_lengths)} characters\")\n",
    "print(f\"   Median length: {np.median(desc_lengths):.0f} characters\")\n",
    "\n",
    "# Check for any failed descriptions\n",
    "failed_descriptions = df[df[description_col].astype(str).str.contains('Error generating description', na=False)]\n",
    "print(f\"\\nğŸ” Quality Check:\")\n",
    "print(f\"   Successful descriptions: {len(df) - len(failed_descriptions)}\")\n",
    "print(f\"   Failed descriptions: {len(failed_descriptions)}\")\n",
    "if len(failed_descriptions) > 0:\n",
    "    print(f\"   Failed categories: {list(failed_descriptions['SubCategory'])}\")\n",
    "\n",
    "print(f\"\\nâœ… Data ready for embedding generation!\")\n",
    "print(f\"ğŸ¯ Using '{description_col}' for embedding generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca0711",
   "metadata": {},
   "source": [
    "## ğŸ¤– 2. Systematic Embedding Model Comparison Framework\n",
    "\n",
    "We'll test multiple embedding models and save results systematically for comparison:\n",
    "\n",
    "### ğŸ“Š **Embedding Models to Test:**\n",
    "\n",
    "1. **OpenAI Models** (if available):\n",
    "   - `text-embedding-3-large` (High quality, expensive)\n",
    "   - `text-embedding-3-small` (Good quality, cost-effective)\n",
    "   - `text-embedding-ada-002` (Baseline)\n",
    "\n",
    "2. **Multilingual Sentence Transformers**:\n",
    "   - `AIDA-UPM/mstsb-paraphrase-multilingual-mpnet-base-v2` (Arabic-English optimized)\n",
    "   - `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (Fast multilingual)\n",
    "   - `sentence-transformers/all-MiniLM-L6-v2` (Lightweight baseline)\n",
    "\n",
    "3. **Arabic-Specific Models**:\n",
    "   - `aubmindlab/bert-base-arabertv02` (Arabic BERT)\n",
    "   - `CAMeL-Lab/bert-base-arabic-camelbert-mix` (Arabic specialized)\n",
    "\n",
    "### ğŸ¯ **Evaluation Metrics:**\n",
    "- **Generation Speed** (embeddings/second)\n",
    "- **Model Size** (memory usage)\n",
    "- **Similarity Quality** (manual validation)\n",
    "- **Arabic-English Handling** (code-switching performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Systematic Embedding Generation Framework\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "import psutil\n",
    "import logging\n",
    "\n",
    "# Import custom modules for embedding generation\n",
    "sys.path.append('../src')\n",
    "from embedding_manager import EmbeddingManager\n",
    "from faiss_handler import FAISSHandler\n",
    "\n",
    "def save_embedding_experiment(embeddings, model_name, metadata, df):\n",
    "    \"\"\"Save embedding experiment results with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create experiment directory\n",
    "    experiment_dir = Path(f'../results/experiments/phase2_embeddings')\n",
    "    experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Clean model name for filename\n",
    "    clean_model_name = model_name.replace('/', '_').replace('-', '_')\n",
    "    \n",
    "    # Save embeddings\n",
    "    embeddings_file = experiment_dir / f'embeddings_{clean_model_name}_{timestamp}.npy'\n",
    "    np.save(embeddings_file, embeddings)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata['timestamp'] = timestamp\n",
    "    metadata['model_name'] = model_name\n",
    "    metadata['embeddings_file'] = str(embeddings_file)\n",
    "    metadata['data_shape'] = embeddings.shape\n",
    "    \n",
    "    metadata_file = experiment_dir / f'embeddings_{clean_model_name}_{timestamp}_metadata.json'\n",
    "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Save data mapping (category to embedding index)\n",
    "    data_mapping = df[['SubCategory', 'Service', 'SubCategory2']].copy()\n",
    "    data_mapping['embedding_index'] = range(len(data_mapping))\n",
    "    \n",
    "    mapping_file = experiment_dir / f'data_mapping_{clean_model_name}_{timestamp}.csv'\n",
    "    data_mapping.to_csv(mapping_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"ğŸ’¾ Saved embedding experiment '{clean_model_name}' to:\")\n",
    "    print(f\"   ğŸ“„ Embeddings: {embeddings_file}\")\n",
    "    print(f\"   ğŸ“„ Metadata: {metadata_file}\")\n",
    "    print(f\"   ğŸ“„ Mapping: {mapping_file}\")\n",
    "    \n",
    "    return embeddings_file, metadata_file, mapping_file\n",
    "\n",
    "def get_available_models():\n",
    "    \"\"\"Get list of available embedding models\"\"\"\n",
    "    models = {\n",
    "        'openai': {\n",
    "            'text-embedding-3-large': {'size': 3072, 'cost': 'high', 'quality': 'excellent'},\n",
    "            'text-embedding-3-small': {'size': 1536, 'cost': 'medium', 'quality': 'good'},\n",
    "            'text-embedding-ada-002': {'size': 1536, 'cost': 'low', 'quality': 'baseline'}\n",
    "        },\n",
    "        'sentence_transformers': {\n",
    "            'AIDA-UPM/mstsb-paraphrase-multilingual-mpnet-base-v2': {\n",
    "                'size': 768, 'specialization': 'Arabic-English', 'quality': 'excellent'\n",
    "            },\n",
    "            'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': {\n",
    "                'size': 384, 'specialization': 'Multilingual', 'quality': 'good'\n",
    "            },\n",
    "            'sentence-transformers/all-MiniLM-L6-v2': {\n",
    "                'size': 384, 'specialization': 'General', 'quality': 'baseline'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def benchmark_embedding_generation(embedding_manager, texts, model_name):\n",
    "    \"\"\"Benchmark embedding generation performance\"\"\"\n",
    "    print(f\"ğŸš€ Benchmarking {model_name}...\")\n",
    "    \n",
    "    # Memory before\n",
    "    process = psutil.Process()\n",
    "    memory_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    # Time the embedding generation\n",
    "    start_time = time.time()\n",
    "    embeddings = embedding_manager.generate_embeddings(texts)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Memory after\n",
    "    memory_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    # Calculate metrics\n",
    "    generation_time = end_time - start_time\n",
    "    texts_per_second = len(texts) / generation_time\n",
    "    memory_used = memory_after - memory_before\n",
    "    \n",
    "    metadata = {\n",
    "        'model_name': model_name,\n",
    "        'total_texts': len(texts),\n",
    "        'generation_time_seconds': generation_time,\n",
    "        'texts_per_second': texts_per_second,\n",
    "        'memory_used_mb': memory_used,\n",
    "        'embedding_dimension': embeddings.shape[1],\n",
    "        'embedding_dtype': str(embeddings.dtype)\n",
    "    }\n",
    "    \n",
    "    print(f\"   â±ï¸  Generation time: {generation_time:.2f} seconds\")\n",
    "    print(f\"   ğŸš€ Speed: {texts_per_second:.2f} texts/second\")\n",
    "    print(f\"   ğŸ’¾ Memory used: {memory_used:.1f} MB\")\n",
    "    print(f\"   ğŸ“Š Embedding shape: {embeddings.shape}\")\n",
    "    \n",
    "    return embeddings, metadata\n",
    "\n",
    "print(\"ğŸ¤– EMBEDDING GENERATION FRAMEWORK READY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show available models\n",
    "available_models = get_available_models()\n",
    "\n",
    "print(\"ğŸ“Š Available Embedding Models:\")\n",
    "for provider, models in available_models.items():\n",
    "    print(f\"\\nğŸ”§ {provider.upper()}:\")\n",
    "    for model_name, specs in models.items():\n",
    "        print(f\"   â€¢ {model_name}\")\n",
    "        for key, value in specs.items():\n",
    "            print(f\"     - {key}: {value}\")\n",
    "\n",
    "print(f\"\\nâœ… Framework ready for systematic embedding generation!\")\n",
    "print(f\"ğŸ¯ Will test multiple models and save all results with timestamps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Generate Embeddings with Specified HuggingFace Model\n",
    "\n",
    "# Primary model specified in requirements\n",
    "PRIMARY_MODEL = 'AIDA-UPM/mstsb-paraphrase-multilingual-mpnet-base-v2'\n",
    "\n",
    "print(f\"ğŸ¯ GENERATING EMBEDDINGS WITH PRIMARY MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š Model: {PRIMARY_MODEL}\")\n",
    "print(f\"ğŸ“„ Data: {len(df)} categories\")\n",
    "print(f\"ğŸ“ Using column: {description_col}\")\n",
    "\n",
    "try:\n",
    "    # Initialize embedding manager with HuggingFace model\n",
    "    print(f\"\\nğŸš€ Initializing EmbeddingManager...\")\n",
    "    embedding_manager = EmbeddingManager(\n",
    "        provider='huggingface',\n",
    "        model_name=PRIMARY_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… EmbeddingManager initialized successfully!\")\n",
    "    print(f\"ğŸ“Š Model loaded: {embedding_manager.model_name}\")\n",
    "    \n",
    "    # Prepare texts for embedding\n",
    "    texts = df[description_col].astype(str).tolist()\n",
    "    print(f\"ğŸ“ Prepared {len(texts)} texts for embedding\")\n",
    "    \n",
    "    # Show sample texts\n",
    "    print(f\"\\nğŸ“„ Sample texts to embed:\")\n",
    "    for i, text in enumerate(texts[:3]):\n",
    "        print(f\"   {i+1}. {text[:100]}...\")\n",
    "    \n",
    "    # Generate embeddings with benchmarking\n",
    "    print(f\"\\nğŸš€ Generating embeddings...\")\n",
    "    embeddings, metadata = benchmark_embedding_generation(\n",
    "        embedding_manager, texts, PRIMARY_MODEL\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… EMBEDDING GENERATION SUCCESSFUL!\")\n",
    "    print(f\"ğŸ“Š Generated {embeddings.shape[0]} embeddings\")\n",
    "    print(f\"ğŸ“ Embedding dimension: {embeddings.shape[1]}\")\n",
    "    print(f\"ğŸ”¢ Data type: {embeddings.dtype}\")\n",
    "    \n",
    "    # Save the experiment\n",
    "    print(f\"\\nğŸ’¾ Saving experiment results...\")\n",
    "    embeddings_file, metadata_file, mapping_file = save_embedding_experiment(\n",
    "        embeddings, PRIMARY_MODEL, metadata, df\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ‰ PRIMARY MODEL EMBEDDING GENERATION COMPLETE!\")\n",
    "    print(f\"ğŸ“ Files saved successfully\")\n",
    "    print(f\"ğŸ¯ Ready for FAISS index creation and similarity testing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error generating embeddings: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Will try alternative approach...\")\n",
    "    \n",
    "    # Fallback: Try with sentence-transformers directly\n",
    "    try:\n",
    "        print(f\"ğŸ”„ Trying direct sentence-transformers approach...\")\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        \n",
    "        model = SentenceTransformer(PRIMARY_MODEL)\n",
    "        print(f\"âœ… Model loaded directly: {PRIMARY_MODEL}\")\n",
    "        \n",
    "        # Generate embeddings\n",
    "        start_time = time.time()\n",
    "        embeddings = model.encode(texts, show_progress_bar=True)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'model_name': PRIMARY_MODEL,\n",
    "            'total_texts': len(texts),\n",
    "            'generation_time_seconds': end_time - start_time,\n",
    "            'texts_per_second': len(texts) / (end_time - start_time),\n",
    "            'embedding_dimension': embeddings.shape[1],\n",
    "            'method': 'direct_sentence_transformers'\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Fallback successful!\")\n",
    "        print(f\"ğŸ“Š Shape: {embeddings.shape}\")\n",
    "        print(f\"â±ï¸  Time: {metadata['generation_time_seconds']:.2f}s\")\n",
    "        \n",
    "        # Save the experiment\n",
    "        embeddings_file, metadata_file, mapping_file = save_embedding_experiment(\n",
    "            embeddings, PRIMARY_MODEL, metadata, df\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ’¾ Fallback results saved successfully!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Fallback also failed: {e2}\")\n",
    "        embeddings = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a45fe",
   "metadata": {},
   "source": [
    "## ğŸ”„ 3. Additional Embedding Models Comparison\n",
    "\n",
    "Now let's systematically test additional models and save all results for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ Systematic Multi-Model Embedding Comparison\n",
    "\n",
    "def test_multiple_models(texts, models_to_test):\n",
    "    \"\"\"Test multiple embedding models and save results\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        print(f\"\\nğŸ¤– Testing model: {model_name}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Try with EmbeddingManager first\n",
    "            embedding_manager = EmbeddingManager(\n",
    "                provider='huggingface',\n",
    "                model_name=model_name\n",
    "            )\n",
    "            \n",
    "            embeddings, metadata = benchmark_embedding_generation(\n",
    "                embedding_manager, texts, model_name\n",
    "            )\n",
    "            \n",
    "            # Save experiment\n",
    "            embeddings_file, metadata_file, mapping_file = save_embedding_experiment(\n",
    "                embeddings, model_name, metadata, df\n",
    "            )\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'status': 'success',\n",
    "                'embeddings': embeddings,\n",
    "                'metadata': metadata,\n",
    "                'files': {\n",
    "                    'embeddings': embeddings_file,\n",
    "                    'metadata': metadata_file,\n",
    "                    'mapping': mapping_file\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… {model_name} completed successfully!\")\n",
    "            \n",
    "            # Clean up memory\n",
    "            del embedding_manager, embeddings\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {model_name} failed: {e}\")\n",
    "            \n",
    "            # Try direct sentence-transformers approach\n",
    "            try:\n",
    "                print(f\"ğŸ”„ Trying fallback for {model_name}...\")\n",
    "                from sentence_transformers import SentenceTransformer\n",
    "                \n",
    "                model = SentenceTransformer(model_name)\n",
    "                start_time = time.time()\n",
    "                embeddings = model.encode(texts, show_progress_bar=True)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                metadata = {\n",
    "                    'model_name': model_name,\n",
    "                    'total_texts': len(texts),\n",
    "                    'generation_time_seconds': end_time - start_time,\n",
    "                    'texts_per_second': len(texts) / (end_time - start_time),\n",
    "                    'embedding_dimension': embeddings.shape[1],\n",
    "                    'method': 'direct_sentence_transformers'\n",
    "                }\n",
    "                \n",
    "                # Save experiment\n",
    "                embeddings_file, metadata_file, mapping_file = save_embedding_experiment(\n",
    "                    embeddings, model_name, metadata, df\n",
    "                )\n",
    "                \n",
    "                results[model_name] = {\n",
    "                    'status': 'success_fallback',\n",
    "                    'embeddings': embeddings,\n",
    "                    'metadata': metadata,\n",
    "                    'files': {\n",
    "                        'embeddings': embeddings_file,\n",
    "                        'metadata': metadata_file,\n",
    "                        'mapping': mapping_file\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                print(f\"âœ… {model_name} completed with fallback!\")\n",
    "                \n",
    "                # Clean up memory\n",
    "                del model, embeddings\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"âŒ {model_name} fallback also failed: {e2}\")\n",
    "                results[model_name] = {\n",
    "                    'status': 'failed',\n",
    "                    'error': str(e2)\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define models to test (in addition to the primary model)\n",
    "ADDITIONAL_MODELS = [\n",
    "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',  # Fast multilingual\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',  # Lightweight baseline\n",
    "    'sentence-transformers/distiluse-base-multilingual-cased'  # DistilUSE multilingual\n",
    "]\n",
    "\n",
    "print(f\"ğŸ”„ TESTING ADDITIONAL EMBEDDING MODELS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š Primary model already tested: {PRIMARY_MODEL}\")\n",
    "print(f\"ğŸ”„ Additional models to test: {len(ADDITIONAL_MODELS)}\")\n",
    "\n",
    "for i, model in enumerate(ADDITIONAL_MODELS, 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "\n",
    "# Option to test additional models (set to True to run)\n",
    "TEST_ADDITIONAL_MODELS = False  # Change to True to test additional models\n",
    "\n",
    "if TEST_ADDITIONAL_MODELS:\n",
    "    print(f\"\\nğŸš€ Starting additional model testing...\")\n",
    "    \n",
    "    # Test additional models\n",
    "    additional_results = test_multiple_models(texts, ADDITIONAL_MODELS)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nğŸ“Š ADDITIONAL MODELS TESTING SUMMARY:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model_name, result in additional_results.items():\n",
    "        status = result['status']\n",
    "        if status == 'success':\n",
    "            metadata = result['metadata']\n",
    "            print(f\"\\nâœ… {model_name}\")\n",
    "            print(f\"   Status: Success\")\n",
    "            print(f\"   Dimension: {metadata['embedding_dimension']}\")\n",
    "            print(f\"   Speed: {metadata['texts_per_second']:.2f} texts/sec\")\n",
    "            print(f\"   Time: {metadata['generation_time_seconds']:.2f}s\")\n",
    "        elif status == 'success_fallback':\n",
    "            metadata = result['metadata']\n",
    "            print(f\"\\nğŸ”„ {model_name}\")\n",
    "            print(f\"   Status: Success (fallback)\")\n",
    "            print(f\"   Dimension: {metadata['embedding_dimension']}\")\n",
    "            print(f\"   Speed: {metadata['texts_per_second']:.2f} texts/sec\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ {model_name}\")\n",
    "            print(f\"   Status: Failed\")\n",
    "            print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ All additional model testing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâ¸ï¸  Additional model testing skipped (TEST_ADDITIONAL_MODELS = False)\")\n",
    "    print(f\"ğŸ’¡ To test additional models, set TEST_ADDITIONAL_MODELS = True and re-run\")\n",
    "    print(f\"ğŸ¯ Primary model ({PRIMARY_MODEL}) results are already saved and ready!\")\n",
    "\n",
    "print(f\"\\nâœ… EMBEDDING GENERATION PHASE COMPLETE\")\n",
    "print(f\"ğŸ“ All results saved with timestamps in: ../results/experiments/phase2_embeddings/\")\n",
    "print(f\"ğŸ”„ No data overwritten - all experiments preserved!\")\n",
    "print(f\"\\nğŸš€ READY FOR FAISS INDEX CREATION AND SIMILARITY TESTING\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
